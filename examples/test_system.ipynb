{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration notebook\n",
    "\n",
    "This notebook is a quick demonstration of the main features and primitives of SystemFlow which you can use to investigate component and system level trade-offs in scientific computing systems. This tutorial assumes basic familiarity with Python features such as dictionaries and classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import sys\n",
    "from ruamel.yaml import YAML\n",
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "from collections import namedtuple\n",
    "from copy import deepcopy\n",
    "from functools import reduce\n",
    "from typing import Callable, Any\n",
    "from itertools import accumulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes and objects we'll use to build a model of a system are defined in *Systemflow.node*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from systemflow.node import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In the SystemFlow framework, information originates at sources such as sensors. Sensors (and other system components) can be managed by a set of *parameters*. These can change on long time-scales, such as by replacing or upgrading equipment, but stay constant once the system is built.\n",
    "\n",
    "For instance, let's consider a simple system: we have a 2D image sensor which acquires images at a fixed rate and carries out a convolutional filter on these images to detect certain features of interest. We may wish to consider relationships such as the number of convolutional filters used, the impact on power, and effectiveness of the system at detecting features. Over time, we may expect the resolution of the sensor to go up, and we can predict the associated demand on power and classification performance to change as well. \n",
    "\n",
    "## Messages\n",
    "Let's start by looking at how information is transmitted through the system via *messages*. A *message* contains *fields* which represent sample-varying data, such as:\n",
    "* Images\n",
    "* Image features\n",
    "* Classification decisions\n",
    "\n",
    "A message also contains *properties*, which do not vary by sample, such as:\n",
    "* Formats & encoding\n",
    "\n",
    "Let's look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Message(# Fields \n",
    "                {\"Image data (B)\": 24e6}, # 24 MB of image data\n",
    "                # Parameters\n",
    "                {\"Image resolution (n,n,n)\": (4000, 6000, 8), # 4k x 6k pixels captured at 8 bits each\n",
    "                 \"Sample rate (Hz)\": 1000})  #1000 frames per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Image data (B)': 24000000.0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Image resolution (n,n,n)': (4000, 6000, 8), 'Sample rate (Hz)': 1000}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutations\n",
    "Once originated, messages' information can be *mutated* by transforms which add additional fields and properties. Let's look at one example, a Convolve operation which uses weighted kernels to extract features such as oriented edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolve(Mutate):\n",
    "    \"\"\"\n",
    "    Models the operations and resources used during a convolution operation.\n",
    "    \"\"\"\n",
    "    def __init__(self, name: str = \"Convolve\"):\n",
    "        #Input message fields\n",
    "        msg_fields = VarCollection()\n",
    "    \n",
    "        #Input message properties\n",
    "        msg_properties = VarCollection(resolution = \"resolution (n,n)\",\n",
    "                                       sample_rate = \"sample rate (Hz)\",)\n",
    "\n",
    "        #Input host parameters\n",
    "        host_parameters = VarCollection(kernel = \"kernel (n,n)\",\n",
    "                                        filters = \"filters (n)\",)\n",
    "        \n",
    "        inputs = MutationInputs(msg_fields, msg_properties, host_parameters)\n",
    "\n",
    "        #Output message fields\n",
    "        msg_fields = VarCollection(features = \"features (B)\",)\n",
    "\n",
    "        #Output message properties\n",
    "        msg_properties = VarCollection()\n",
    "\n",
    "        #Output host properties\n",
    "        host_properties = VarCollection(ops = \"conv ops (n)\",)\n",
    "\n",
    "        outputs = MutationOutputs(msg_fields, msg_fields, host_properties)\n",
    "\n",
    "        super().__init__(name, inputs, outputs)\n",
    "\n",
    "\n",
    "    def transform(self, message: Message, component: 'Component'):\n",
    "        \"\"\"Previously, we defined the inputs and outputs which this mutation has. Now, we create concrete\n",
    "           transforms which take those inputs and set the outputs\"\"\"\n",
    "        #access the required fields/properties/parameters\n",
    "        res = message.properties[self.inputs.msg_properties.resolution]\n",
    "        kernel_x = component.parameters[self.inputs.host_parameters.kernel][0]\n",
    "        kernel_y = component.parameters[self.inputs.host_parameters.kernel][1]\n",
    "        filters = component.parameters[self.inputs.host_parameters.filters]\n",
    "        rate = message.properties[self.inputs.msg_properties.sample_rate]\n",
    "\n",
    "        #calculate the number of ops required for the kernel\n",
    "        kernel_ops = kernel_x * kernel_y * filters\n",
    "        steps_x = (res[0] - kernel_x) // kernel_x\n",
    "        steps_y = (res[1] - kernel_y) // kernel_y\n",
    "        kernel_repeats = steps_x * steps_y\n",
    "\n",
    "        #calculate the number of ops required for the kernel\n",
    "        transform_operations = kernel_ops * kernel_repeats * rate\n",
    "\n",
    "        \"\"\"Above, we access the properties from the input message and host component required by the mutation,\n",
    "           and calculate the outputs. These are stored in dictionaries and accessed by the host component to update\n",
    "           its own properties and output message:\"\"\"\n",
    "        msg_fields = {self.outputs.msg_fields.features: np.prod((steps_x, steps_y, filters)),}\n",
    "        msg_properties = {}\n",
    "        component_properties = {self.outputs.host_properties.ops: transform_operations,}\n",
    "\n",
    "        return msg_fields, msg_properties, component_properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each mutation, the process is the same: the input message fields, properties, and the parameters controlling the mutation are declared. The informational outputs and properties of this \"mutating\" transform are declared, and can change the outgoing message or impart properties on the host component executing this mutation.\n",
    "\n",
    "We've mentioned the host component a few times now, so let's look at this next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components\n",
    "\n",
    "A component is a piece of hardware which executes an algorithm implementing a mutation. In the case of our convolve operation, this could be a CPU, GPU, an FPGA, or custom chip (ASIC). \n",
    "\n",
    "Components can host one or more mutations which are executed sequentially. A component such as a CPU can apply multiple functions, such as *threshold*, *crop*, and *convolve* - but for now, we start with an image_sensor hosting *CollectImage*, which produces a message holding image data and associated properties. \n",
    "\n",
    "For each mutation, we need to know which parameters must be set on the host. We can see which parameters are required by a sequence of mutations by using *collect_parameters.* This returns a *VarCollection* that holds as class members each parameter required by the mutations. This allows you to skip copying and pasting string definitions all over the place!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc_img = collect_parameters([CollectImage()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarCollection(\n",
       "    resolution='resolution (n,n)',\n",
       "    bitdepth='bit depth (n)',\n",
       "    readout='readout latency (s)',\n",
       "    pixelenergy='pixel energy (J)',\n",
       "    sample_rate='sample rate (Hz)'\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing the set of parameters we need, we instantiate them as part of the hosting component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_sensor = Component(\"Image sensor\",\n",
    "                    [CollectImage(),],\n",
    "                    parameters = {vc_img.resolution: (4000, 6000),\n",
    "                     vc_img.bitdepth: 16,\n",
    "                     vc_img.readout: 1e-3,\n",
    "                     vc_img.pixelenergy: 1e-6,\n",
    "                     vc_img.sample_rate: 1000})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we've defined our first component - now, how do we link it to another component such as a CPU hosting image processing algorithms? The definition for the second component follows a similar format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg0 = Message({}, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Message(fields={'image data (B)': np.float64(48000000.0), 'readout latency (s)': 0.001}, properties={'resolution (n,n)': (4000, 6000), 'bitdepth (n)': 16, 'sample rate (Hz)': 1000}),\n",
       " {'sensor power (W)': np.float64(24.0)})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CollectImage()(msg0, image_sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_mutations = [Convolve(),\n",
    "                GaussianClassify(),\n",
    "                DataRate(),\n",
    "                ClassifiedStorageRate(),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc_cpu = collect_parameters(cpu_mutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarCollection(\n",
       "    kernel='kernel (n,n)',\n",
       "    filters='filters (n)',\n",
       "    skill='skill (1)',\n",
       "    variance='variance (1)',\n",
       "    reduction='reduction (%)'\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = Component(\"CPU\",\n",
    "                cpu_mutations,\n",
    "                parameters = {vc_cpu.kernel: (5, 5), #this kernel is 5x5 pixels...\n",
    "                    vc_cpu.filters: 8, #with 8 filters\n",
    "                    vc_cpu.skill: 3, # these features inform a classifier with a separation between null and positive distributions of 3.0\n",
    "                    vc_cpu.variance: 1, # and each distribution has a variance of 1.0\n",
    "                    vc_cpu.reduction: 0.9}) # and this classifier aims to discard 90% of data from the input distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links & ExecutionGraphs\n",
    "\n",
    "To connect these nodes (the image sensor and CPU) and inspect their trends as parameters are varied, we'll construct an *ExecutionGraph.* An ExecutionGraph contains all the nodes which implement a directed data processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we define the nodes\n",
    "nodes = [image_sensor, cpu]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've defined the nodes, but we also need to connect them via *Links.* Links transport data from one node to another, and can model the effects of this process via a single *Transport* function. Similar to mutations, *Transport* functions offer a template to describe the effect of moving data across the link by introduction new message fields, properties, and host properties: for instance, error rates, correction algorithms, and power can be modeled using the Transport function. For this example, we will use the *DefaultLink* which simply transports messages from one node to another without modifying the messages through a Transport function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [DefaultLink(\"Sensor -> CPU\", # A name for the link\n",
    "                    nodes[0].name, # The sending (TX) node\n",
    "                    nodes[1].name),] # The receiving (RX) node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined our nodes and links, an ExecutionGraph can be instantiated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph = ExecutionGraph(\"Sense/Convolve/Classify\", nodes, links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you call an ExecutionGraph, it recursively handles passing messages from node to node, originating blank messages at each \"leaf\" node and propagating them upwards to the \"root\" node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_2 = simple_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a new graph, with new properties such as \"output message\" stored at each node and the output properties from each mutation instantiated at each component. We can inspect the final component by inspecting the *root_node*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image data (B)': np.float64(48000000.0),\n",
       " 'readout latency (s)': 0.001,\n",
       " 'features (B)': np.int64(7664008),\n",
       " 'contingency (2x2)': array([[882,  17],\n",
       "        [ 17,  82]]),\n",
       " 'total data (B)': np.float64(55664008.0)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_2.root_node.output_msg.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resolution (n,n)': (4000, 6000),\n",
       " 'sample rate (Hz)': 1000,\n",
       " 'bitdepth (n)': 16,\n",
       " 'error matrix (2p, 2p)': array([[0.98055646, 0.17499203],\n",
       "        [0.01944354, 0.82500797]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_2.root_node.output_msg.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can look at other nodes, messages, and properties by looking up nodes in the graph by name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sensor power (W)': np.float64(24.0)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_2.get_node(image_sensor.name).properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each ExecutionGraph is instantiated at iteration 1, with each successive call increasing that number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_2.iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interlinking multiple ExecutionGraphs which affect one another allows us to simulate feedback, with the output from one graph influencing another which loops back to the first. We'll look at this functionality in more complex examples with steering. \n",
    "\n",
    "For now, let's move onto a slightly more complex example with two inputs. This will allow us to demonstrate some further functionality necessary for more interesting setups. We'll create a new ExecutionGraph which hosts an additional component, a thermocouple measuring the temperature of the sample being imaged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "thermocouple_mutations = [CollectTemperature(),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc_thm = collect_parameters(thermocouple_mutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarCollection(\n",
       "    bitdepth='temperature bitdepth (n)',\n",
       "    sample_rate='sample rate (Hz)',\n",
       "    sensor_power='thermocouple power (W)'\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc_thm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see that the variable collection for a thermocouple includes a sampling rate. What happens if this sample rate is different from another in the system?\n",
    "\n",
    "## Merges\n",
    "\n",
    "A message can only include one value per unique field and property, therefore, one value has to be selected. This is done using *Merges* on a node. The default merge behavior simply selects the first value out of any which are in conflict. However, this might not lead to the desired behavior, and so the user is warned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg0 = Message({}, {\"Sample rate (Hz)\": 1000})\n",
    "msg1 = Message({}, {\"Sample rate (Hz)\": 1200})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No merge provided for Sample rate (Hz), taking first value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Message(fields={}, properties={'Sample rate (Hz)': 1000})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OverwriteMerge()([msg0, msg1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of this theoretical experiment where we measure the associated temperature for every image, the additional temperature sample aren't needed - they may be interpolated or discarded to match each image, and thus end up matching the lower framerate of the image sensor. We can write a new merge to take the lowest sample rate following this behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RateMerge(Merge):\n",
    "    def __init__(self):\n",
    "        # A merge allows you to set a function used to reduce a collection for\n",
    "        # each desired message field and property. Here, we take the minimum\n",
    "        # value of the sample rate of incoming messages:\n",
    "        super().__init__({}, {vc_img.sample_rate: np.min})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can attach this Merge to the component accepting both messages as inputs which merged together. In this example, this is the CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = Component(\"CPU\",\n",
    "                cpu_mutations,\n",
    "                parameters = {vc_cpu.kernel: (5, 5), #this kernel is 5x5 pixels...\n",
    "                    vc_cpu.filters: 8, #...with 8 filters\n",
    "                    vc_cpu.skill: 3, # these features inform a classifier with a separation between null and positive distributions of 3.0\n",
    "                    vc_cpu.variance: 1, # and each distribution has a variance of 1.0\n",
    "                    vc_cpu.reduction: 0.9}, # and this classifier aims to discard 90% of data from the input distribution\n",
    "                merge = RateMerge(),) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now, let's add a component hosting the thermocouple, link them, and create a new ExecutionGraph with two leaf input sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "thermocouple = Component(\"Thermocouple\",\n",
    "                    [CollectTemperature(),],\n",
    "                    {vc_thm.bitdepth: 16,\n",
    "                     vc_thm.sample_rate: 1200,\n",
    "                     vc_thm.sensor_power: 1e-3,},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [thermocouple, image_sensor, cpu]\n",
    "\n",
    "links = [DefaultLink(\"Thermocouple -> CPU\",\n",
    "                     thermocouple.name,\n",
    "                     cpu.name),\n",
    "        DefaultLink(\"Image sensor -> CPU\",\n",
    "                    image_sensor.name,\n",
    "                    cpu.name)]\n",
    "\n",
    "two_input_graph = ExecutionGraph(\"Sense/Convolve/Classify, 2 Inputs\", nodes, links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_graph = two_input_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can inspect the message and check that the sample rate has been correctly set to 1000 Hz using our new Merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_graph.root_node.output_msg.properties[vc_img.sample_rate]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "Looking for the value we want in each message, component, and so forth is tedious, especially if we're constructing many graphs with multiple iterations each. We can define additional functions, *Metrics*, which are stored in an ExecutionGraph and automatically 'grab' these values and attach them to the graph for easy reference.\n",
    "\n",
    "Let's look at one example to examine how much power the convolution operation is taking given a baseline estimate of power per operation. We can examine all the propertiest produced on the hosts in a graph, and choose one for the metric to transform into the value we're interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CPU': {'conv ops (n)': np.int64(191600200000),\n",
       "  'storage rate (B/s)': array([ 1082305.33432831, 45923251.61719932])},\n",
       " 'Thermocouple': {'thermocouple power (W)': 0.001},\n",
       " 'Image sensor': {'sensor power (W)': np.float64(24.0)}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_graph.get_all_node_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarCollection(\n",
       "    ops='conv ops (n)'\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Convolve().outputs.host_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvPower(Metric):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"Convolution Power\", \n",
    "                         [],\n",
    "                         [\"conv ops (n)\"])\n",
    "        \n",
    "    def metric(self, message: Message, properties: dict):\n",
    "        matches = self.graph_matches(properties)\n",
    "        op_power = 1e-10\n",
    "        power = matches[0] * op_power\n",
    "\n",
    "        metrics = {\"conv power\": power,}\n",
    "        return metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's modify the graph one more time, adding a metric which we'll examine as the output of an experiment where we vary parameters controlling the operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_input_graph = ExecutionGraph(\"Sense/Convolve/Classify, 2 Inputs\", nodes, links, metrics=[ConvPower(),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_graph = two_input_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see that the metric values we've define are automatically produced as features of the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv power': np.float64(19.16002)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_graph.metric_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to locate all values with a unit (such as power (W)), we can also use a regex inside the metric and reduce over the matched values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SensorPower(Metric):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"Convolution Power\", \n",
    "                         [],\n",
    "                         [Regex(r\"power \\(W\\)\")])\n",
    "        \n",
    "    def metric(self, message: Message, properties: dict):\n",
    "        matches = self.graph_matches(properties)\n",
    "        total_power = np.sum(matches)\n",
    "        metrics = {\"sensor power\": total_power,}\n",
    "        return metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_input_graph = ExecutionGraph(\"Sense/Convolve/Classify, 2 Inputs\", nodes, links, metrics=[ConvPower(), SensorPower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_graph = two_input_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv power': np.float64(19.16002), 'sensor power': np.float64(24.001)}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_graph.metric_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's put it all together to demonstrate the main purpose of SystemFlow: being able to rapidly link, vary, and examine the effects of changing parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration\n",
    "\n",
    "Let's imagine that we've established an empirical relationship between two elements: the number of features used in the convolutional kernel, and the performance of the classifier - by adding more features, we can improve the separation of the classifier between null and positive distributions. However, this comes at the cost of increased computational power. Using the relationship we've found, let's sweep through these values and examine the power it takes to reach different levels of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_filters(filters: int, exg: ExecutionGraph):\n",
    "    # an empirical relationship we assume between the classifier skill and number of filters\n",
    "    new_skill = 4 * np.log10(filters)\n",
    "    new_params = {\"CPU\": {vc_cpu.skill: new_skill,\n",
    "                          vc_cpu.filters: filters,}}\n",
    "    # we can simply call an existing graph with new parameters\n",
    "    new_exg = exg.with_updated_parameters(new_params)()\n",
    "    # and extract the performance of the classifier\n",
    "    cont = new_exg.root_node.output_msg.fields[\"contingency (2x2)\"]\n",
    "    #then convert this to an F1 score\n",
    "    tn, fn = get_rejected(cont)\n",
    "    fp, tp = get_passed(cont)\n",
    "    f1 = (2 * tp) / (2 * tp + fp * fn)\n",
    "    power = new_exg.metric_values[\"conv power\"]\n",
    "    return power, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filters = np.arange(1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(map(lambda x: sweep_filters(x, two_input_graph), n_filters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines",
         "name": "Power",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          2.3950025,
          4.790005,
          7.1850075,
          9.58001,
          11.9750125,
          14.370015,
          16.7650175,
          19.16002,
          21.5550225,
          23.950025,
          26.3450275,
          28.74003,
          31.1350325,
          33.530035,
          35.9250375,
          38.32004,
          40.7150425,
          43.110045,
          45.5050475
         ]
        },
        {
         "line": {
          "color": "red"
         },
         "mode": "lines",
         "name": "F1 Score",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          0.0024906600249066002,
          0.020015801948907033,
          0.06455203116304953,
          0.15334773218142547,
          0.2831541218637993,
          0.42748091603053434,
          0.5471698113207547,
          0.6896551724137931,
          0.7896995708154506,
          0.8378378378378378,
          0.8826291079812206,
          0.9223300970873787,
          0.9552238805970149,
          0.9552238805970149,
          0.9797979797979798,
          0.9797979797979798,
          0.9949238578680203,
          0.9949238578680203,
          0.9949238578680203
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "height": 600,
        "legend": {
         "title": {
          "text": "Metrics"
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Power and F1 Score By Convolution Filters"
        },
        "width": 800,
        "xaxis": {
         "title": {
          "text": "Filters"
         }
        },
        "yaxis": {
         "title": {
          "text": "Power (W)"
         }
        },
        "yaxis2": {
         "overlaying": "y",
         "range": [
          0,
          1
         ],
         "side": "right",
         "title": {
          "text": "F1 Score"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Add Power trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=n_filters,\n",
    "    y=stacked[:,0],\n",
    "    mode='lines',\n",
    "    name='Power',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "\n",
    "# Add F1 Score trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=n_filters,\n",
    "    y=stacked[:,1],\n",
    "    mode='lines',\n",
    "    name='F1 Score',\n",
    "    line=dict(color='red'),\n",
    "    yaxis=\"y2\"\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title_text='Power and F1 Score By Convolution Filters',\n",
    "    xaxis_title='Filters',\n",
    "    yaxis_title='Power (W)',\n",
    "    yaxis2=dict(\n",
    "        title=\"F1 Score\",\n",
    "        overlaying=\"y\",\n",
    "        side=\"right\",\n",
    "        range=[0, 1]\n",
    "    ),\n",
    "    legend_title_text='Metrics',\n",
    "    width = 800,\n",
    "    height = 600\n",
    ")\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "systemflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
